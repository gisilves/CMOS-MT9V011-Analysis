{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:05:05.998955Z",
     "start_time": "2019-11-29T16:05:05.995125Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:05:07.631735Z",
     "start_time": "2019-11-29T16:05:07.620697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.3'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"CMOS MT9V011 Cluster Detection\"\"\"\n",
    "\n",
    "#Import libraries\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import blob_log\n",
    "\n",
    "import numpy as np\n",
    "from numpy import interp\n",
    "np.version.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:28:00.644266Z",
     "start_time": "2019-11-29T16:28:00.638560Z"
    }
   },
   "outputs": [],
   "source": [
    "#Files directory\n",
    "DATADIR = \"/nfs/NASPG/BTData/Jul2012_CMOS_data/MT9V011_Firenze_2012_07_13/TEST/\"\n",
    "#DATADIR = \"/nfs/NASPG/BTData/Jul2012_CMOS_data/MT9V011_Firenze_2012_07_13/16_MT9V011_017_G01_050ms_3MeV_-60/\"\n",
    "#DATADIR = sys.argv[1]\n",
    "\n",
    "PEDS = np.zeros((307200,1))\n",
    "PEDS[: , :] = np.nan\n",
    "\n",
    "CLUSTERS = pd.DataFrame({\"Max\":[], \"Sum\":[], \"Size\":[], \"row\":[],\"column\":[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:22:11.063870Z",
     "start_time": "2019-11-29T16:22:10.337655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16_MT9V011_017_G01_050ms_3MeV_-60_00002_fr0000.txt for threshold computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate threshold for pedestal calculation\n",
    "if not os.path.isfile(DATADIR + \"pedestals.npy\"):\n",
    "    RAW_VALUES = np.array(0)\n",
    "    for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR),\n",
    "                                                '*.txt'))):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing \" + _filename + \" for threshold computation\")\n",
    "        RAW_VALUES = np.append(RAW_VALUES, np.loadtxt(DATADIR + _filename, dtype=\"int\"))\n",
    "        THRESH = (RAW_VALUES.mean() + 2 * RAW_VALUES.std()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:22:13.512081Z",
     "start_time": "2019-11-29T16:22:13.376989Z"
    }
   },
   "outputs": [],
   "source": [
    "im = np.loadtxt(DATADIR + _filename)\n",
    "im = im.reshape(307200,1)\n",
    "if im.shape == (307200,1):\n",
    "    mask = im < THRESH  # mask of pixels under threshold (good for pedestals)\\\n",
    "    im[im >= THRESH] = np.nan  # to prevent adding events with signal\n",
    "    PEDS = np.concatenate((PEDS, im), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:22:04.356057Z",
     "start_time": "2019-11-29T16:22:04.352672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307200, 2)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PEDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:28:20.274124Z",
     "start_time": "2019-11-29T16:28:20.249501Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate or (load) Pedestals\n",
    "if not os.path.isfile(DATADIR + \"pedestals.npy\"):\n",
    "    for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR),\n",
    "                                                '*.txt'))):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing \" + _filename + \" for pedestals computation\")\n",
    "        im = np.loadtxt(DATADIR + _filename)\n",
    "        if im.shape == (307200,):\n",
    "            mask = im < THRESH  # mask of pixels under threshold (good for pedestals)\n",
    "            im[im >= THRESH] = np.nan  # to prevent adding events with signal\n",
    "            im = np.atleast_2d(im).T\n",
    "            PEDS = np.concatenate((PEDS, im), axis=1)\n",
    "        else:\n",
    "            continue\n",
    "    #PEDS = np.nanmean(PEDS,axis=1)\n",
    "    PEDS.dump(DATADIR + \"pedestals.npy\")\n",
    "else:\n",
    "    PEDS = np.load(DATADIR + \"pedestals.npy\", allow_pickle=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:29:00.287683Z",
     "start_time": "2019-11-29T16:29:00.264135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsilvest/anaconda3/envs/gigi/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307200,)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(PEDS,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T16:28:25.705102Z",
     "start_time": "2019-11-29T16:28:25.017187Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16_MT9V011_017_G01_050ms_3MeV_-60_00000_fr0000.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:00<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16_MT9V011_017_G01_050ms_3MeV_-60_00001_fr0000.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:00<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16_MT9V011_017_G01_050ms_3MeV_-60_00002_fr0000.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find clusters in every frame\n",
    "for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR), '*.txt'))):\n",
    "    print(\"Processing \" + _filename)\n",
    "    frame = np.loadtxt(DATADIR + _filename, dtype=\"int\")\n",
    "\n",
    "    if frame.shape == PEDS.shape:\n",
    "        frame = frame - PEDS\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    frame = frame.reshape(480, 640)\n",
    "    _temp = interp(frame, [0, 1024], [0, 1])\n",
    "    \n",
    "    #Find \"blobs\"\n",
    "    blobs_log = blob_log(_temp, max_sigma=50, num_sigma=50, threshold=.05)\n",
    "    blobs_log[:, 2] = blobs_log[:, 2] * 2 * sqrt(2)\n",
    "    \n",
    "    for _x, _y, _r in blobs_log:\n",
    "        _min_y = (_y - _r).astype(int)\n",
    "        _max_y = (_y + _r).astype(int)\n",
    "        _min_x = (_x - _r).astype(int)\n",
    "        _max_x = (_x + _r).astype(int)\n",
    "        _subim = frame[_min_x:_max_x, _min_y:_max_y]\n",
    "        CLUSTERS = CLUSTERS.append({'Max': np.max(_subim), 'Sum' : np.sum(_subim),\n",
    "                                    'Size' : _subim.size,\n",
    "                                    'row' : _x,\n",
    "                                    'column' : _y},\n",
    "                                   ignore_index=True)\n",
    "    \n",
    "    CLUSTERS.to_feather(DATADIR + \"clusters.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gigi] *",
   "language": "python",
   "name": "conda-env-gigi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
