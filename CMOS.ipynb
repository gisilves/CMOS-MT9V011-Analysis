{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:17:33.525724Z",
     "start_time": "2019-12-02T10:17:33.334121Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:17:36.459701Z",
     "start_time": "2019-12-02T10:17:35.921100Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"CMOS MT9V011 Cluster Detection\"\"\"\n",
    "\n",
    "#Import libraries\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import blob_log\n",
    "\n",
    "import numpy as np\n",
    "from numpy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:45:15.667898Z",
     "start_time": "2019-12-02T09:45:15.662770Z"
    }
   },
   "outputs": [],
   "source": [
    "#Files directory\n",
    "#DATADIR = \"/nfs/NASPG/BTData/Jul2012_CMOS_data/MT9V011_Firenze_2012_07_13/TEST/\"\n",
    "DATADIR = \"/nfs/NASPG/BTData/Jul2012_CMOS_data/MT9V011_Firenze_2012_07_13/16_MT9V011_017_G01_050ms_3MeV_-60/\"\n",
    "#DATADIR = sys.argv[1]\n",
    "\n",
    "#Initialize pedestal array and clusters dataframe\n",
    "PEDS = np.zeros((307200,1))\n",
    "PEDS[: , :] = np.nan #initialize to NaN so they can be easily excluded from mean calculation\n",
    "CLUSTERS = pd.DataFrame({\"Max\":[], \"Sum\":[], \"Size\":[], \"row\":[],\"column\":[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:03:33.503129Z",
     "start_time": "2019-12-02T10:03:33.491432Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate threshold for pedestal calculation\n",
    "if not os.path.isfile(DATADIR + \"pedestals.npy\"):\n",
    "    RAW_VALUES = np.array(0)\n",
    "    for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR),\n",
    "                                                '*.txt'))):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing \" + _filename + \" for threshold computation\")\n",
    "        RAW_VALUES = np.append(RAW_VALUES, np.loadtxt(DATADIR + _filename, dtype=\"int\"))\n",
    "        #threshold is based on distribution of all values, assuming signal pixel are a minority on every frame\n",
    "        THRESH = (RAW_VALUES.mean() + 2 * RAW_VALUES.std()).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:49:53.818106Z",
     "start_time": "2019-12-02T09:45:21.391555Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate or (load) Pedestals\n",
    "if not os.path.isfile(DATADIR + \"pedestals.npy\"):\n",
    "    for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR),\n",
    "                                                '*.txt'))):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing \" + _filename + \" for pedestals computation\")\n",
    "        im = np.loadtxt(DATADIR + _filename)\n",
    "        if im.shape == (307200,):#check if frame is complete\n",
    "            mask = im < THRESH  # mask of pixels under threshold (good for pedestals)\n",
    "            im[im >= THRESH] = np.nan  # to prevent adding events with signal we set them to NaN\n",
    "            im = np.atleast_2d(im).T #to force a 2D array\n",
    "            PEDS = np.concatenate((PEDS, im), axis=1) #each pixel as a value from all the frames\n",
    "        else:\n",
    "            continue\n",
    "    #calculate mean and std of each pixel for all the frames ignoring masked values\n",
    "    PEDS = np.array([np.nanmean(PEDS,axis=1), np.nanstd(PEDS,axis=1)]) \n",
    "    PEDS.dump(DATADIR + \"pedestals.npy\")\n",
    "else:\n",
    "    PEDS = np.load(DATADIR + \"pedestals.npy\", allow_pickle=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:16:53.770666Z",
     "start_time": "2019-12-02T10:16:38.250347Z"
    }
   },
   "outputs": [],
   "source": [
    "#Find clusters in every frame\n",
    "for _filename in tqdm(sorted(fnmatch.filter(os.listdir(DATADIR), '*.txt'))):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Processing \" + _filename)\n",
    "    frame = np.loadtxt(DATADIR + _filename, dtype=\"int\")\n",
    "\n",
    "    if frame.shape == PEDS[0].shape: #check if frame is complete\n",
    "        frame = frame - PEDS[0] #pedestal subtraction\n",
    "        frame[np.isnan(frame)] = 0 #convert NaN values to 0 (needed for skimage library)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    frame = frame.reshape(480, 640) #reshape array into VGA image\n",
    "    _temp = interp(frame, [0, 1024], [0, 1]) #convert image to grayscale\n",
    "    \n",
    "    #Find \"blobs\" with Lagrangian of Gaussian algorithm of Skimage library\n",
    "    blobs_log = blob_log(_temp, max_sigma=50, num_sigma=50, threshold=.05)\n",
    "    blobs_log[:, 2] = blobs_log[:, 2] * 2 * sqrt(2)\n",
    "    \n",
    "    for _x, _y, _r in blobs_log:\n",
    "        _min_y = (_y - _r).astype(int)\n",
    "        _max_y = (_y + _r).astype(int)\n",
    "        _min_x = (_x - _r).astype(int)\n",
    "        _max_x = (_x + _r).astype(int)\n",
    "        _subim = frame[_min_x:_max_x, _min_y:_max_y]#retrieve subarray of original value based on Skimage blob location\n",
    "        if np.nanmax(_subim) > 2 * PEDS[1][np.nanargmax(_subim)]:#check if max of subimage is \"seed\" of a cluster (based on ped std of that pixel)\n",
    "            CLUSTERS = CLUSTERS.append({'Max': np.nanmax(_subim), 'Sum' : np.nansum(_subim),\n",
    "                                        'Size' : _subim.size,\n",
    "                                        'row' : _x,\n",
    "                                        'column' : _y},\n",
    "                                       ignore_index=True)#add cluster info to DataFrame\n",
    "    \n",
    "    CLUSTERS.to_feather(DATADIR + \"clusters.feather\")#save clusters to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:14:34.974994Z",
     "start_time": "2019-12-02T09:14:34.969585Z"
    }
   },
   "outputs": [],
   "source": [
    "CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gigi] *",
   "language": "python",
   "name": "conda-env-gigi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
